=== Eval results (from model.evaluate - loss, accuracy, precision, recall, AUC) ===
[1.029132604598999, 0.6164732575416565, 0.7502252459526062, 0.47141239047050476, 0.91164630651474]

=== Global metrics ===
Accuracy: 0.6165
Macro Precision: 0.5984
Weighted Precision: 0.6175
Macro Recall: 0.6082
Weighted Recall: 0.6165
Macro F1: 0.6000
Weighted F1: 0.6140
AUC (OVR): 0.8917

=== Per-class metrics ===
              precision    recall  f1-score   support

           0     0.4995    0.5115    0.5054       960
           1     0.6031    0.7117    0.6529       111
           2     0.4867    0.3585    0.4129      1018
           3     0.8425    0.8323    0.8374      1825
           4     0.5045    0.6447    0.5661      1216
           5     0.5037    0.4759    0.4894      1139
           6     0.7490    0.7227    0.7356       797

    accuracy                         0.6165      7066
   macro avg     0.5984    0.6082    0.6000      7066
weighted avg     0.6175    0.6165    0.6140      7066
