=== Eval results (from model.evaluate - loss, accuracy, precision, recall, AUC) ===
[1.511175274848938, 0.42145484685897827, 0.6828660368919373, 0.1551089733839035, 0.7953670024871826]

=== Global metrics ===
Accuracy: 0.4215
Macro Precision: 0.3785
Weighted Precision: 0.4236
Macro Recall: 0.4011
Weighted Recall: 0.4215
Macro F1: 0.3534
Weighted F1: 0.4008
AUC (OVR): 0.7770

=== Per-class metrics ===
              precision    recall  f1-score   support

           0     0.3755    0.1792    0.2426       960
           1     0.1044    0.5135    0.1735       111
           2     0.3867    0.1424    0.2082      1018
           3     0.5011    0.7370    0.5966      1825
           4     0.3859    0.4145    0.3997      1216
           5     0.3790    0.2941    0.3312      1139
           6     0.5166    0.5270    0.5217       797

    accuracy                         0.4215      7066
   macro avg     0.3785    0.4011    0.3534      7066
weighted avg     0.4236    0.4215    0.4008      7066
