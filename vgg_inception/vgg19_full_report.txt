=== Eval results (from model.evaluate - loss, accuracy, precision, recall, AUC) ===
[1.7388287782669067, 0.3188508450984955, 0.6834170818328857, 0.03849419578909874, 0.6998756527900696]

=== Global metrics ===
Accuracy: 0.3189
Macro Precision: 0.2767
Weighted Precision: 0.3141
Macro Recall: 0.3076
Weighted Recall: 0.3189
Macro F1: 0.2309
Weighted F1: 0.2712
AUC (OVR): 0.6893

=== Per-class metrics ===
              precision    recall  f1-score   support

           0     0.1930    0.0458    0.0741       960
           1     0.0556    0.5045    0.1001       111
           2     0.2936    0.0314    0.0568      1018
           3     0.3874    0.7288    0.5059      1825
           4     0.3062    0.1299    0.1824      1216
           5     0.2650    0.1905    0.2217      1139
           6     0.4365    0.5220    0.4754       797

    accuracy                         0.3189      7066
   macro avg     0.2767    0.3076    0.2309      7066
weighted avg     0.3141    0.3189    0.2712      7066
